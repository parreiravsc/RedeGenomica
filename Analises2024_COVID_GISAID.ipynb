{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# importar bibliotecas\n","import pandas as pd\n","import numpy as np\n","import datetime as dt\n","\n","# ignorar as mensagens de Warning\n","pd.options.mode.chained_assignment = None"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 1 Ler datasets"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 casos de COVID \n","### fonte: https://covid.saude.gov.br/"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Caminho dos datasets dos casos de covid\n","## 2020\n","df_2020_parte1 = 'HIST_PAINEL_COVIDBR_2020_Parte1_29mar2024.csv'\n","df_2020_parte2 = 'HIST_PAINEL_COVIDBR_2020_Parte2_29mar2024.csv'\n","## 2021\n","df_2021_parte1 = 'HIST_PAINEL_COVIDBR_2021_Parte1_29mar2024.csv'\n","df_2021_parte2 = 'HIST_PAINEL_COVIDBR_2021_Parte2_29mar2024.csv'\n","## 2022\n","df_2022_parte1 = 'HIST_PAINEL_COVIDBR_2022_Parte1_29mar2024.csv'\n","df_2022_parte2 = 'HIST_PAINEL_COVIDBR_2022_Parte2_29mar2024.csv'\n","## 2023\n","df_2023_parte1 = 'HIST_PAINEL_COVIDBR_2023_Parte1_29mar2024.csv'\n","df_2023_parte2 = 'HIST_PAINEL_COVIDBR_2023_Parte2_29mar2024.csv'\n","## 2024\n","df_2024_parte1 = 'HIST_PAINEL_COVIDBR_2024_Parte1_29mar2024.csv'\n","\n","# colunas que serão lidas\n","colunas = ['regiao', 'estado', 'municipio', 'data', 'casosNovos']\n","\n","# Carregar dataset dos casos covid\n","df1 = pd.read_csv(df_2020_parte1, sep=';', usecols=colunas)\n","df2 = pd.read_csv(df_2020_parte2, sep=';', usecols=colunas)\n","df3 = pd.read_csv(df_2021_parte1, sep=';', usecols=colunas)\n","df4 = pd.read_csv(df_2021_parte2, sep=';', usecols=colunas)\n","df5 = pd.read_csv(df_2022_parte1, sep=';', usecols=colunas)\n","df6 = pd.read_csv(df_2022_parte2, sep=';', usecols=colunas)\n","df7 = pd.read_csv(df_2023_parte1, sep=';', usecols=colunas)\n","df8 = pd.read_csv(df_2023_parte2, sep=';', usecols=colunas)\n","df9 = pd.read_csv(df_2024_parte1, sep=';', usecols=colunas)\n","\n","# unir os dfs\n","df_casos_original = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9])\n","\n","# excluir os dfs \n","del df1\n","del df2\n","del df3\n","del df4\n","del df5\n","del df6\n","del df7\n","del df8\n","del df9"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["38796900"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# usar só onde a coluna 'município' é 'NaN' (vai filtrar só os casos novos por UF)\n","casos_full_filtrado = df_casos_original[df_casos_original['municipio'].isna()]\n","\n","# dropar coluna 'municipio'\n","casos_full_filtrado = casos_full_filtrado.drop('municipio', axis=1)\n","\n","# remover onde 'regiao == Brasil'\n","casos_full_filtrado = casos_full_filtrado.query('regiao != \"Brasil\"')\n","\n","# dropar colunas 'regiao'\n","casos_full_filtrado = casos_full_filtrado.drop('regiao', axis=1)\n","\n","# total de casos\n","casos_full_filtrado['casosNovos'].sum()"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Genomas depositados no GISAID"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Cerregar dataset com ProbWrongDates (prováveis datas de coleta erradas. fonte: Tiago)\n","df_wrongDate = pd.read_csv('Prob.wrongDates.toExclude.txt', sep='\\t')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Amostras: 252285\n"]}],"source":["# carregar metadados do GISAID (fonte: https://gisaid.org/)\n","# colunas a serem lidas\n","colunas = ['Virus name', 'Accession ID', 'Collection date', \n","           'Location', 'Pango lineage', 'Variant']\n","\n","# ler dataset\n","gisaid_original = pd.read_csv('metadata.tsv', sep='\\t', usecols=colunas)\n","\n","# filtrar apenas amostras do Brasil\n","dados_gisaid = gisaid_original[gisaid_original['Location'].str.contains('Brazil')]\n","\n","# deletar df original\n","del gisaid_original\n","\n","# total de amostras brasileiras\n","print('Amostras:', dados_gisaid.shape[0])"]},{"cell_type":"markdown","metadata":{},"source":["# 2 Pré análise dos dados"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# substituir espaços por underscore nos nomes das colunas\n","dados_gisaid.columns = dados_gisaid.columns. str. replace(' ','_')\n","\n","# renomear a coluna\n","dados_gisaid_renomeado = dados_gisaid.rename(columns={'Pango_lineage': 'Lineage'})"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["'''\n","os gráficos 'genomas/laboratório' considera todos os depósitos, até os 'NAN' ou 'unassigned'\n","'''\n","# fazer uma cópia do dataset para usar nos gráficos de 'genomas/laboratório'\n","df_lab = dados_gisaid.copy()"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# excluir as amostras que estão como 'Unassigned' na linhagem\n","dados_gisaid_renomeado = dados_gisaid_renomeado.query('Lineage != \"Unassigned\"')\n","\n","# excluir as amostras que estão como 'NaN' na linhagem\n","dados_gisaid_renomeado = dados_gisaid_renomeado[dados_gisaid_renomeado['Lineage'].notna()]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["JD.1.2      54\n","JD.1        42\n","XBB.1.5     13\n","JD.1.1       9\n","JD.1.1.1     1\n","Name: Lineage, dtype: int64\n","119\n"]}],"source":["'''\n","Algumas amostras vieram do gisaid classificadas erradas (deveriam ser JD.1 em vez de XBB.1.5).\n","Tiago quem forneceu os 'Accession IDs' das amostras 'XBB.1.5' a serem alteradas para JD.1.* \n","'''\n","# ler o df do Tiago com os 'Accession IDs'\n","df_tiago = pd.read_csv('nextclade_jd.tsv', sep='\\t')\n","# rcolcoar os Accession IDs em uma lista\n","lista_ID = list(df_tiago['accession'])\n","\n","'''\n","separar o df do gisaid em 2 dfs: \n","um sem as amostras do Accession ID do Tiago; \n","o outro só com os Accession ID do Tiago \n","'''\n","# df1 sem os Accession ID do Tiago\n","df_1 = dados_gisaid_renomeado.query('Accession_ID not in @lista_ID')\n","# df2 com os Accession ID do Tiago\n","df_2 = dados_gisaid_renomeado.query('Accession_ID in @lista_ID')\n","\n","# trocar XBB.1.5 por JD.1.* no df2\n","df_2['Lineage'] = 'JD.1.*'\n","df_2['Lineage'].unique()\n","\n","# unir de volta os 2 dfs: df1 + df2\n","dados_gisaid_renomeado_reclassificado = pd.concat([df_1, df_2])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3 Dicionários"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# dicionário para padronizar/corrigir os nomes dos estados\n","dict_nomes_corretos_estados = {\n","    'Brasilia': 'Distrito Federal',\n","    'Sao Paulo': 'São Paulo',\n","    'Goias': 'Goiás',\n","    'Espirito Santo': 'Espírito Santo',\n","    'Federal District': 'Distrito Federal',\n","    'Para': 'Pará',\n","    'Amapa': 'Amapá',\n","    'Maranhao': 'Maranhão',\n","    'Ceara': 'Ceará',\n","    'Piaui': 'Piauí',\n","    'Parana': 'Paraná',\n","    'Rondonia': 'Rondônia',\n","    'Paraiba': 'Paraíba',\n","    'Rio De Janeiro': 'Rio de Janeiro',\n","    'Rio Grande Do Sul': 'Rio Grande do Sul',\n","    'Goais': 'Goiás',\n","    'Porto Alegre': 'Rio Grande do Sul',\n","    'Guapimirim': 'Rio de Janeiro',\n","    'Porto Alegre':  'Rio Grande do Sul',\n","    'ES':  'Espírito Santo',\n","    'RJ': 'Rio de Janeiro',\n","    'PR': 'Paraná',\n","    'Recife': 'Pernambuco',\n","    'Fortaleza': 'Ceará',\n","    'Curitiba': 'Paraná',\n","    'Manaus': 'Amazonas',\n","    'MG': 'Minas Gerais',\n","    'Rcre': 'Acre',\n","    'RN': 'Rio Grande do Norte'}\n","\n","# dicionário para criar as siglas dos Estados\n","dict_estado_para_sigla = {\n","    'São Paulo': 'SP', \n","    'Paraíba': 'PB', \n","    'Sergipe': 'SE',\n","    'Piauí': 'PI',\n","    'Pará': 'PA',\n","    'Maranhão': 'MA',\n","    'Acre': 'AC',\n","    'Amapá': 'AP',\n","    'Ceará': 'CE',\n","    'Espírito Santo': 'ES',\n","    'Rio Grande do Sul': 'RS',\n","    'Minas Gerais': 'MG',\n","    'Santa Catarina': 'SC',\n","    'Roraima': 'RR',\n","    'Alagoas': 'AL',\n","    'Pernambuco': 'PE',\n","    'Rio Grande do Norte': 'RN',\n","    'Mato Grosso': 'MT',\n","    'Paraná': 'PR',\n","    'Mato Grosso do Sul': 'MS',\n","    'Distrito Federal': 'DF',\n","    'Goiás': 'GO',\n","    'Bahia': 'BA',\n","    'Amazonas': 'AM',\n","    'Rondônia': 'RO',\n","    'Rio de Janeiro': 'RJ',\n","    'Tocantins': 'TO'}\n","\n","# mapear o Estado com sua respectiva região \n","dict_sigla_para_regiao = {\n","    \"AC\": \"Norte\", \"AM\": \"Norte\", \"RR\": \"Norte\", \"RO\": \"Norte\", \n","    \"PA\": \"Norte\", \"AP\": \"Norte\", \"TO\": \"Norte\", \n","    \"MA\": \"Nordeste\", \"PI\": \"Nordeste\", \"CE\": \"Nordeste\", \n","    \"RN\": \"Nordeste\", \"PB\": \"Nordeste\", \"PE\": \"Nordeste\",\n","    \"AL\": \"Nordeste\", \"SE\": \"Nordeste\", \"BA\": \"Nordeste\",\n","    \"MT\": \"Centro-oeste\", \"MS\": \"Centro-oeste\", \n","    \"GO\": \"Centro-oeste\", \"DF\": \"Centro-oeste\",\n","    \"SP\": \"Sudeste\", \"RJ\": \"Sudeste\",\n","    \"MG\": \"Sudeste\", \"ES\": \"Sudeste\",\n","    \"PR\": \"Sul\", \"SC\": \"Sul\",\n","    \"RS\": \"Sul\"}\n","\n","# dicionário para criar os nomes dos Estados a partir da sigle \n","# para o df dos Casos de Covid \n","dict_sigla_para_estado = {\n","    'SP': 'São Paulo', \n","    'PB': 'Paraíba', \n","    'SE': 'Sergipe',\n","    'PI': 'Piauí',\n","    'PA': 'Pará',\n","    'MA': 'Maranhão',\n","    'AC': 'Acre',\n","    'AP': 'Amapá',\n","    'CE': 'Ceará',\n","    'ES': 'Espírito Santo',\n","    'RS': 'Rio Grande do Sul',\n","    'MG': 'Minas Gerais',\n","    'SC': 'Santa Catarina',\n","    'RR': 'Roraima',\n","    'AL': 'Alagoas',\n","    'PE': 'Pernambuco',\n","    'RN': 'Rio Grande do Norte',\n","    'MT': 'Mato Grosso',\n","    'PR': 'Paraná',\n","    'MS': 'Mato Grosso do Sul',\n","    'DF': 'Distrito Federal',\n","    'GO': 'Goiás',\n","    'BA': 'Bahia',\n","    'AM': 'Amazonas',\n","    'RO': 'Rondônia',\n","    'RJ': 'Rio de Janeiro',\n","    'TO': 'Tocantins'}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4 Funções"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["'''\n","Remove as entradas duplicadas de acordo com o 'Virus name'\n","(Essa função talvez não seja mais necessária)\n","'''\n","def remove_duplicatas(df):\n","  # pegar o índice das linhas duplicadas\n","  duplicatas_virus_name = df[df['Virus_name'].duplicated()].index\n","  # excluir essas linhas pelo índice\n","  df2 = df.drop(duplicatas_virus_name)\n","  # pegar o índice das linhas duplicadas\n","  duplicatas_accession_id = df2[df2['Accession_ID'].duplicated()].index\n","  df2 = df2.drop(duplicatas_accession_id)\n","  print('Total de linhas duplicadas removidas:', df.shape[0]-df2.shape[0], 'Done!')\n","  return df2\n","\n","\n","'''\n","Remove as amostras com ProbWrongDate (datas de coleta provavelmente erradas)\n","'''\n","def remove_wrondDate(df, df_wrongDate):  \n","  # lista com os valores da coluna 'Virus name' das amostras do dataset 'Prob.wrongDates.toExclude' \n","  wrongDate_virus_names = df_wrongDate[\"Virus.name\"].values\n","  # remover as amostras com ProbWrongDates dos dados do GISAID\n","  df2 = df.query(\"Virus_name not in @wrongDate_virus_names\")\n","  print('Total de linhas com ProbWrongDate removidas:', df.shape[0]-df2.shape[0], 'Done!')\n","  return df2 \n","\n","\n","'''\n","Extrai o Estado das informações contidas na variável 'Location'.\n","Retorna o mesmo df com uma nova variável 'Estado'.\n","Retorna NaN caso não haja a informação do Estado.\n","'''\n","def cria_estado(df):\n","  # função lambda para extrair o elemento do índice 2 (que é o Estado) de cada linha\n","  # retorna 'NaN' caso não tenha o Estado no índice 2\n","  extrai = lambda lista: lista[2] if len(lista) >= 3 else np.NaN\n","  # cria a coluna 'Estado' e aplica a função lambda 'extrai'\n","  df['Estado'] = df['Location'].str.split('/').apply(extrai)\n","  # remover espaços iniciais e finais que possam estar no nome do Estado\n","  df['Estado'] = df['Estado'].str.strip()\n","  print(df['Estado'].unique())\n","  print('Estados únicos =', df['Estado'].nunique(), 'Done!')\n","  return df\n","\n","\n","'''\n","Corrige os nomes dos Estados\n","'''\n","def corrige_nomes_estados(df, dict_nomes_corretos_estados):\n","  # substituir pelos nomes padronizados\n","  df['Estado'] = df['Estado'].replace(dict_nomes_corretos_estados)\n","  print(df['Estado'].unique())\n","  print('Estados únicos - corrigidos =', df['Estado'].nunique(), 'Done!')\n","  return df\n","\n","\n","''''\n","Cria as colunas 'UF' e 'Região'\n","'''\n","def cria_siglas_e_regiao(df, dict_siglas_estados, dict_regiao):\n","  # criar a coluna 'UF' a partir do 'Estado'\n","  df['UF'] = df['Estado'].replace(dict_siglas_estados)\n","   # criar a coluna 'Região' a partir da 'UF'\n","  df['Região'] = df['UF'].map(dict_regiao)  \n","  print('UFs únicas', df['UF'].nunique())\n","  print('Regiões únicas', df['Região'].nunique(), 'Done!') \n","  return df\n","\n","\n","'''\n","Extrai as informações de mês e ano (= fperíodo) da coluna 'Collection date' \n","'''\n","def cria_mes_ano(df):\n","  # converter coluna para datetime\n","  df['Collection_date'] = pd.to_datetime(df['Collection_date'])    \n","  # criar a variável 'Mes'\n","  df['Mes'] = df['Collection_date'].dt.month \n","  # criar a variável 'Ano'\n","  df['Ano'] = df['Collection_date'].dt.year \n","  # criar a data ormato 'ANO-MES'\n","  df['Data'] = (df['Ano']).astype('str') + '-' + (df['Mes']).astype('str')\n","  df['Data'] = pd.to_datetime(df[f'Data'])\n","  # dicionário com o número do mês e seu nome (3 letras iniciais)\n","  dict_mes = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Abr', 5: 'Mai', 6: 'Jun',\n","              7: 'Jul', 8: 'Ago', 9: 'Set', 10: 'Out', 11: 'Nov', 12: 'Dez'}\n","  # criar a coluna 'Mes_nome' com o nome do mês\n","  df['Mes_nome'] = df['Mes'].map(dict_mes)\n","  # concatenar mês + ano como strings\n","  df['Período'] = df['Mes_nome'] + ' ' + (df['Ano']).astype('str')\n","  # remover a coluna 'Mes_nome'\n","  df.drop('Mes_nome', axis=1, inplace=True)\n","  print('Collection_date: datas extraídas. Done!')\n","  return df\n","\n","\n","'''\n","Identifica laboratório: sequências da 'Fiocrus' e 'Outros'\n","'''\n","def identifica_lab(df):\n","  # colocar tudo em minúsculo\n","  df['Virus_name'] = df['Virus_name'].str.lower()\n","  # procura as linhas que tem 'fiocruz' na coluna 'Virus_name'; \n","  # recebe True se tiver 'fiocruz'; recebe False caso contrário\n","  df['Laboratório'] = df['Virus_name'].str.contains(\"fiocruz\")\n","  # dicionário para substituir o True e o False\n","  lab = {True: 'FIOCRUZ',\n","         False: 'Outros'}  \n","  # criar a variável 'Laboratório' que vai receber de qual lab o vírus foi sequenciado      \n","  # substituir True e False por 'FIOCRUZ' e 'Outros'\n","  df['Laboratório'] = df['Laboratório'].map(lab)  \n","  print('Labs identificados. Done!')\n","  return df\n","\n","\n","'''\n","Linhagens: para os gráficos do final do dashboard (série histórica).\n","Vai agrupar as sub-linhagens em sua 'linhagem-mãe' (o asterisco * indica que há sub-linhagens)\n","'''\n","def cria_linhagem(df):\n","  # remover, pelo índice, as 'P.1' que foram classificadas erradas no começo da pandemia\n","  indices_P1 = df[df['Lineage'].str.startswith('P.1')].query('Ano == \"2020\" and Mes in [\"09\", \"10\", \"11\"]').index\n","  df = df.drop(indices_P1)\n","  # classificar as 'P.1.1' e 'P.1.2' como 'P.1'\n","  df['Lineage'] = df['Lineage'].apply(lambda x: 'P.1' if (x == 'P.1.1' or x == 'P.1.2') else x)\n","\n","  # Delta\n","  df['Linhagem'] = df['Lineage'].apply(lambda x: 'B.1.617.2+AY.* (Delta)' if (x.startswith('AY.') or x == 'B.1.617.2') else x)\n","  # Alfa\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'B.1.1.7 (Alfa)' if (x.startswith('Q') or x == 'B.1.1.7') else x)\n","  # Beta\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'B.1.351 (Beta)' if x.startswith('B.1.351') else x)\n","  # Gama\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'P.1.* (Gama)' if x.startswith('P.1') else x)\n","  # Omicron\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'BA.1.* (Omicron)' if x.startswith('BA.1') else x)\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'BA.2.* (Omicron)' if x.startswith('BA.2') else x)\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'BA.4.* (Omicron)' if x.startswith('BA.4') else x)\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'BA.5.* (Omicron)' if (x.startswith('BA.5') or\\\n","                                                                         x.startswith('BE') or\\\n","                                                                         x.startswith('BQ') or\\\n","                                                                         x.startswith('DL')) else x)\n","  ## XBB.1.5.70 - não agrupar essa sub-linhagem com as demais XBB.*\n","  xbb70 = df[df['Lineage'].str.startswith('XBB.1.5.70')]['Lineage'].unique()\n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'XBB.* (Omicron)' if (x.startswith('XBB') and x not in xbb70) else x) \n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'FE.1.* (Omicron)' if x.startswith('FE.1') else x)  \n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'XBB.1.5.70.*+GK.* (Omicron)' if (x.startswith('XBB.1.5.70') or x.startswith('GK')) else x)  \n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'JD.1.* (Omicron)' if (x.startswith('JD.1')) else x) \n","  df['Linhagem'] = df['Linhagem'].apply(lambda x: 'JN.1.*+BA.2.86.* (Omicron)' if (x.startswith('JN.1') or x.startswith('BA.2.86.')) else x) \n","  return df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4.1 Chamar funções"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1638637559493,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"yBwQh_u-sBzY","outputId":"a28d894a-76ab-4df2-83f0-c9ab51a89a24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total de linhas duplicadas removidas: 1 Done!\n","Total de linhas com ProbWrongDate removidas: 24 Done!\n","['Rio de Janeiro' 'Sao Paulo' 'Minas Gerais' 'Piaui' 'Pernambuco' 'Bahia'\n"," 'Ceara' 'Amazonas' 'Santa Catarina' 'Rondonia' 'Mato Grosso do Sul'\n"," 'Rio Grande do Sul' 'Goias' 'Parana' 'Para' 'Paraiba' 'Espirito Santo'\n"," 'Acre' 'Alagoas' 'Tocantins' 'Rio Grande do Norte' 'Sergipe' 'Amapa' nan\n"," 'Federal District' 'Mato Grosso' 'Maranhao' 'Roraima' 'RN' 'RJ']\n","Estados únicos = 29 Done!\n"]}],"source":["# remover duplicatas\n","dados = remove_duplicatas(dados_gisaid_renomeado_reclassificado)\n","\n","# remover amostras com prováveis datas de coleta erradas\n","dados = remove_wrondDate(dados, df_wrongDate)\n","\n","# criar coluna 'Estado'\n","dados = cria_estado(dados)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1638638376586,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"naf52jf68an3","outputId":"391a4771-5dd0-411b-9dfc-7eeb12a268c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Rio de Janeiro' 'São Paulo' 'Minas Gerais' 'Piauí' 'Pernambuco' 'Bahia'\n"," 'Ceará' 'Amazonas' 'Santa Catarina' 'Rondônia' 'Mato Grosso do Sul'\n"," 'Rio Grande do Sul' 'Goiás' 'Paraná' 'Pará' 'Paraíba' 'Espírito Santo'\n"," 'Acre' 'Alagoas' 'Tocantins' 'Rio Grande do Norte' 'Sergipe' 'Amapá' nan\n"," 'Distrito Federal' 'Mato Grosso' 'Maranhão' 'Roraima']\n","Estados únicos - corrigidos = 27 Done!\n","UFs únicas 27\n","Regiões únicas 5 Done!\n","Collection_date: datas extraídas. Done!\n","Labs identificados. Done!\n"]}],"source":["# corrigir nomes dos Estados que vieram errados do gisaid\n","dados = corrige_nomes_estados(dados, dict_nomes_corretos_estados)\n","\n","# criar as colunas 'UF' e 'Região'\n","dados = cria_siglas_e_regiao(dados, dict_estado_para_sigla, dict_sigla_para_regiao)\n","\n","# criar colunas com 'mes', 'ano', 'período'\n","dados = cria_mes_ano(dados)\n","\n","# criar a coluna 'Laboratório'\n","dados = identifica_lab(dados)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 5 Análises - gráficos Genomas sequenciados/Laboratório"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total de linhas duplicadas removidas: 1 Done!\n","Total de linhas com ProbWrongDate removidas: 24 Done!\n","Collection_date: datas extraídas. Done!\n","Labs identificados. Done!\n"]}],"source":["# chamar novamente algumas das funções, porém agora é no dataset que copiamos no início\n","df_lab = remove_duplicatas(df_lab)\n","df_lab = remove_wrondDate(df_lab, df_wrongDate)\n","df_lab = cria_mes_ano(df_lab)\n","df_lab = identifica_lab(df_lab)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Laboratório</th>\n","      <th>Período</th>\n","      <th>Quantidade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>97</th>\n","      <td>2024-01-01</td>\n","      <td>Outros</td>\n","      <td>Jan 2024</td>\n","      <td>770</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>2024-02-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Fev 2024</td>\n","      <td>246</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>2024-02-01</td>\n","      <td>Outros</td>\n","      <td>Fev 2024</td>\n","      <td>366</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>2024-03-01</td>\n","      <td>Outros</td>\n","      <td>Mar 2024</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Data Laboratório   Período  Quantidade\n","97  2024-01-01      Outros  Jan 2024         770\n","98  2024-02-01     FIOCRUZ  Fev 2024         246\n","99  2024-02-01      Outros  Fev 2024         366\n","100 2024-03-01      Outros  Mar 2024          21"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# agrupar por 'Laboratório' e 'Data' e fazer a contagem\n","agrupado_laboratorio = df_lab[['Virus_name', 'Laboratório', 'Data', 'Período']]\\\n",".groupby(['Data', 'Laboratório', 'Período']).count().reset_index()\n","\n","# renomear colunas\n","agrupado_laboratorio.rename(columns={'Virus_name': 'Quantidade'}, inplace=True)\n","agrupado_laboratorio.tail(4)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"Sa5a7yPaGaY_"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Laboratório</th>\n","      <th>Período</th>\n","      <th>Quantidade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>97</th>\n","      <td>2024-01-01</td>\n","      <td>Outros</td>\n","      <td>Jan 2024</td>\n","      <td>770</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>2024-02-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Fev 2024</td>\n","      <td>246</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>2024-02-01</td>\n","      <td>Outros</td>\n","      <td>Fev 2024</td>\n","      <td>366</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>2024-03-01</td>\n","      <td>Outros</td>\n","      <td>Mar 2024</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>2024-03-01</td>\n","      <td>Outros</td>\n","      <td>Mar 2024</td>\n","      <td>21</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Data Laboratório   Período  Quantidade\n","97  2024-01-01      Outros  Jan 2024         770\n","98  2024-02-01     FIOCRUZ  Fev 2024         246\n","99  2024-02-01      Outros  Fev 2024         366\n","100 2024-03-01      Outros  Mar 2024          21\n","101 2024-03-01      Outros  Mar 2024          21"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","USAR APENAS QUANDO NÃO HOUVER AMOSTRAS DA FIOCRUZ DEPOSITADAS NO ÚLTIMO MÊS, MAS HÁ SOMENTE AMOSTRAS DO 'OUTROS'\n","O NÚMERO DO ÍNDICE PRECISA SER ATUALIZADO CONFORME NOVOS MESES SÃO ADICIONADOS AOS DADOS\n","'''\n","# adiciona a última linha no final do próprio df \n","agrupado_laboratorio = agrupado_laboratorio.append(agrupado_laboratorio.iloc[100], ignore_index=True)\n","agrupado_laboratorio.tail()"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"e20j4Wn8GrWC"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Laboratório</th>\n","      <th>Período</th>\n","      <th>Quantidade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>97</th>\n","      <td>2024-01-01</td>\n","      <td>Outros</td>\n","      <td>Jan 2024</td>\n","      <td>770</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>2024-02-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Fev 2024</td>\n","      <td>246</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>2024-02-01</td>\n","      <td>Outros</td>\n","      <td>Fev 2024</td>\n","      <td>366</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>2024-03-01</td>\n","      <td>Outros</td>\n","      <td>Mar 2024</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>2024-03-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Mar 2024</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Data Laboratório   Período  Quantidade\n","97  2024-01-01      Outros  Jan 2024         770\n","98  2024-02-01     FIOCRUZ  Fev 2024         246\n","99  2024-02-01      Outros  Fev 2024         366\n","100 2024-03-01      Outros  Mar 2024          21\n","101 2024-03-01     FIOCRUZ  Mar 2024           0"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","USAR APENAS QUANDO NÃO HOUVER AMOSTRAS DA FIOCRUZ DEPOSITADAS NO ÚLTIMO MÊS, MAS HÁ SOMENTE AMOSTRAS DO 'OUTROS'\n","O NÚMERO DO ÍNDICE PRECISA SER ATUALIZADO CONFORME NOVOS MESES SÃO ADICIONADOS AOS DADOS\n","'''\n","# substitui o nome do lab por 'FIOCRUZ'\n","agrupado_laboratorio.loc[101, 'Laboratório'] = 'FIOCRUZ'\n","# substitui a quantidade de genoma depositado por zero\n","agrupado_laboratorio.loc[101, 'Quantidade'] = 0\n","agrupado_laboratorio.tail()"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Laboratório</th>\n","      <th>Período</th>\n","      <th>Quantidade</th>\n","      <th>Acumulado</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>98</th>\n","      <td>2024-02-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Fev 2024</td>\n","      <td>246</td>\n","      <td>83413</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>2024-02-01</td>\n","      <td>Outros</td>\n","      <td>Fev 2024</td>\n","      <td>366</td>\n","      <td>168826</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>2024-03-01</td>\n","      <td>Outros</td>\n","      <td>Mar 2024</td>\n","      <td>21</td>\n","      <td>168847</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>2024-03-01</td>\n","      <td>FIOCRUZ</td>\n","      <td>Mar 2024</td>\n","      <td>0</td>\n","      <td>83413</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Data Laboratório   Período  Quantidade  Acumulado\n","98  2024-02-01     FIOCRUZ  Fev 2024         246      83413\n","99  2024-02-01      Outros  Fev 2024         366     168826\n","100 2024-03-01      Outros  Mar 2024          21     168847\n","101 2024-03-01     FIOCRUZ  Mar 2024           0      83413"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["# calcular valores acumulados\n","acumulado = agrupado_laboratorio.set_index('Laboratório').groupby(level=0).cumsum()['Quantidade']\n","\n","# criar a coluna 'Acumulado' dos valores acumulados\n","agrupado_laboratorio['Acumulado'] = acumulado.values\n","agrupado_laboratorio.tail(4)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["252260"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# total de genomas depositados\n","agrupado_laboratorio['Quantidade'].sum()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# traduzir: EN e ES\n","dic_regex_EN = {'Fev': 'Feb', 'Abr': 'Apr', 'Mai': 'May',\n","                'Ago': 'Aug', 'Set': 'Sep', 'Out': 'Oct', 'Dez': 'Dec'}\n","\n","dic_regex_ES = {'Jan': 'Ene', 'Fev': 'Feb', 'Mai': 'May',\n","                'Set': 'Sep', 'Out': 'Oct', 'Dez': 'Dic'}\n","\n","agrupado_laboratorio_EN = agrupado_laboratorio.rename(columns={'Data': 'Date',\n","                                                               'Laboratório': 'Laboratory',\n","                                                               'Período': 'Period',\n","                                                               'Quantidade': 'Quantity',\n","                                                               'Acumulado': 'Cumullative'})\n","\n","agrupado_laboratorio_ES = agrupado_laboratorio.rename(columns={'Data': 'Fecha',\n","                                                               'Laboratório': 'Laboratorio',\n","                                                               'Quantidade': 'Cantidad'})\n","\n","agrupado_laboratorio_EN = agrupado_laboratorio_EN.replace({'Outros': 'Others'})\n","agrupado_laboratorio_EN = agrupado_laboratorio_EN.replace(regex=dic_regex_EN)\n","\n","agrupado_laboratorio_ES = agrupado_laboratorio_ES.replace({'Outros': 'Otros'})\n","agrupado_laboratorio_ES = agrupado_laboratorio_ES.replace(regex=dic_regex_ES)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# exportar\n","agrupado_laboratorio.to_csv('dfGenomasLaboratorio_PT.csv', index=False)\n","agrupado_laboratorio_EN.to_csv('dfGenomasLaboratorio_EN.csv', index=False)\n","agrupado_laboratorio_ES.to_csv('dfGenomasLaboratorio_ES.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SiPG3PCk6fYk"},"source":["# 6 Análises - gráficos das variantes mais recentes (a partir de Jan 2023)"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["Fev 2023    2655\n","Jan 2023    2239\n","Out 2023    2184\n","Nov 2023    1705\n","Set 2023    1693\n","Dez 2023    1684\n","Mar 2023    1663\n","Jan 2024    1402\n","Abr 2023    1308\n","Mai 2023    1241\n","Jun 2023     939\n","Ago 2023     803\n","Fev 2024     612\n","Jul 2023     442\n","Mar 2024      21\n","Name: Período, dtype: int64"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["# filtrar amostras coletadas a partir de 2023\n","dados_voc = dados.query('Ano in [2023, 2024]')\n","dados_voc['Período'].value_counts()"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["# remover onde 'Lineage' é None\n","dados_voc = dados_voc[dados_voc['Lineage'] != 'None']\n","# remover onde 'Lineage' é NaN\n","dados_voc = dados_voc[dados_voc['Lineage'].notna()]\n","\n","# criar a coluna 'Variante' para trabalhar nela - deixar a 'Lineage' com os dados originais\n","dados_voc['Variante'] = dados_voc['Lineage']"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1638638768719,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"J26FT3aoQ0Vs"},"outputs":[{"data":{"text/plain":["Outras                         6785\n","XBB.1.5.70.*+GK.* (Omicron)    3530\n","JD.1.* (Omicron)               3158\n","XBB.1.5.* (Omicron)            2680\n","JN.1.*+BA.2.86.* (Omicron)     2365\n","FE.1.* (Omicron)               1885\n","EG.5.* (Omicron)                148\n","HA.1.* (Omicron)                 40\n","Name: Variantes relevantes, dtype: int64"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# salvar em listas as linhagens e suas sub-linhagens (essas serão mostradas nos gráficos)\n","xbb = dados_voc[dados_voc['Variante'].str.startswith('XBB.1.5')]['Variante'].unique()\n","gk = dados_voc[dados_voc['Variante'].str.startswith('GK')]['Variante'].unique()\n","fe = dados_voc[dados_voc['Variante'].str.startswith('FE.1')]['Variante'].unique()\n","ha = dados_voc[dados_voc['Variante'].str.startswith('HA.1')]['Variante'].unique()\n","eg = dados_voc[dados_voc['Variante'].str.startswith('EG.5')]['Variante'].unique()\n","jd = dados_voc[dados_voc['Variante'].str.startswith('JD.1')]['Variante'].unique()\n","ba = dados_voc[dados_voc['Variante'].str.startswith('BA.2.86.')]['Variante'].unique()\n","jn = dados_voc[dados_voc['Variante'].str.startswith('JN.1')]['Variante'].unique()\n","\n","# colocar os valores em apenas uma lista\n","variantes_relevantes = [*xbb, *fe, *ha, *eg, *jd, *gk, *jn, *ba]  \n","\n","# criar coluna 'Variantes relevantes' \n","# 'Variantes relevantes' são mostradas no gráfico\n","# Outras variantes entram como 'Outras'\n","dados_voc['Variantes relevantes'] = dados_voc['Variante'].apply(lambda x: x if (x in variantes_relevantes) else 'Outras')\n","\n","# separar a XBB.1.5.70 e suas sub-linhagens das demais XBB.1.5\n","xbb_1_5_70 = dados_voc[dados_voc['Variante'].str.startswith('XBB.1.5.70')]['Variante'].unique()\n","excluir = [*xbb_1_5_70]\n","\n","# XBB.1.5* (não incluir a XBB.1.5.70 e suas sub-linhagens)\n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'XBB.1.5.* (Omicron)' if (x.startswith('XBB.1.5') and x not in excluir) else x) \n","# XBB.1.5.70.*+GK.*\n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'XBB.1.5.70.*+GK.* (Omicron)' if (x.startswith('XBB.1.5.70') or x.startswith('GK')) else x)  \n","# HA.1.* \n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'HA.1.* (Omicron)' if (x.startswith('HA.1')) else x) \n","# FE.1.* \n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'FE.1.* (Omicron)' if (x.startswith('FE.1')) else x) \n","# EG.5.* \n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'EG.5.* (Omicron)' if (x.startswith('EG.5')) else x) \n","# JD.1.* \n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'JD.1.* (Omicron)' if (x.startswith('JD.1')) else x) \n","# JN.1 \n","dados_voc['Variantes relevantes'] = dados_voc['Variantes relevantes'].apply(lambda x: 'JN.1.*+BA.2.86.* (Omicron)' if (x.startswith('JN.1') or x.startswith('BA.2.86.')) else x) \n","\n","dados_voc['Variantes relevantes'].value_counts()      "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Período</th>\n","      <th>Região</th>\n","      <th>Estado</th>\n","      <th>Variantes relevantes</th>\n","      <th>Quantidade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-01-01</td>\n","      <td>Jan 2023</td>\n","      <td>Centro-oeste</td>\n","      <td>Distrito Federal</td>\n","      <td>Outras</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-01-01</td>\n","      <td>Jan 2023</td>\n","      <td>Centro-oeste</td>\n","      <td>Goiás</td>\n","      <td>Outras</td>\n","      <td>107</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Data   Período        Região            Estado Variantes relevantes  \\\n","0 2023-01-01  Jan 2023  Centro-oeste  Distrito Federal               Outras   \n","1 2023-01-01  Jan 2023  Centro-oeste             Goiás               Outras   \n","\n","   Quantidade  \n","0           4  \n","1         107  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# selecionar apenas algumas colunas\n","agrupado_voc = dados_voc[['Virus_name', 'Região', 'Estado', 'Data', \n","                          'Período', 'Variantes relevantes']]\n","\n","# agrupar pelo período, região, variante, lab e contar as freqs\n","agrupado_voc = agrupado_voc.groupby(['Data', 'Período', 'Região', 'Estado', \n","                                     'Variantes relevantes']).count()\n","\n","# resetar índice\n","agrupado_voc = agrupado_voc.reset_index()\n","\n","# renomear colunas\n","agrupado_voc = agrupado_voc.rename(columns={'Virus_name': 'Quantidade'})\n","agrupado_voc.head(2)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# traduzir EN e ES\n","dic_replace_regiao_EN = {'Norte': 'North', \n","                         'Nordeste': 'Northeast',\n","                         'Sudeste': 'Southeast', \n","                         'Sul': 'South',\n","                         'Centro-oeste': 'Central-west',\n","                         'Outras': 'Others'}\n","\n","dic_regex_EN = {'Fev': 'Feb', 'Abr': 'Apr', 'Mai': 'May',\n","                'Ago': 'Aug', 'Set': 'Sep', 'Out': 'Oct',\n","                'Dez': 'Dec'}\n","\n","dic_replace_regiao_ES = {'Nordeste': 'Noreste',\n","                         'Sudeste': 'Sureste', \n","                         'Sul': 'Sur',\n","                         'Outras': 'Otras'}\n","\n","dic_regex_ES = {'Jan': 'Ene', 'Fev': 'Feb', 'Mai': 'May',\n","                'Set': 'Sep', 'Out': 'Oct', 'Dez': 'Dic'}    \n","\n","agrupado_voc_EN = agrupado_voc.replace(dic_replace_regiao_EN)\n","agrupado_voc_EN = agrupado_voc_EN.replace(regex=dic_regex_EN)\n","agrupado_voc_EN = agrupado_voc_EN.rename(columns={'Data': 'Date', 'Período': 'Period',\n","                                                  'Região': 'Region', 'Estado': 'State',\n","                                                  'Variante': 'Variant', \n","                                                  'Variantes relevantes': 'Relevant variants',\n","                                                  'Quantidade': 'Quantity'})\n","\n","agrupado_voc_ES = agrupado_voc.replace(dic_replace_regiao_ES)\n","agrupado_voc_ES = agrupado_voc_ES.replace(regex=dic_regex_ES)\n","agrupado_voc_ES = agrupado_voc_ES.rename(columns={'Data': 'Fecha', \n","                                                  'Região': 'Región', \n","                                                  'Quantidade': 'Cantidad'})            "]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# exportar\n","agrupado_voc.to_csv('dfVariantes_PT.csv', index=False)\n","agrupado_voc_EN.to_csv('dfVariantes_EN.csv', index=False)\n","agrupado_voc_ES.to_csv('dfVariantes_ES.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### 6.1 Variantes mais frequentes do último mês (parte superior direita do dashboard)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Atualizar o valor do período para o mês mais recente\n","'''\n","# criar um df só com os depósitos do mês mais recente\n","dfLinMes_PT = agrupado_voc.query('Período == \"Mar 2024\"')[['Variantes relevantes', 'Quantidade']]\n","\n","# renomar coluna\n","dfLinMes_PT = dfLinMes_PT.reset_index().rename(columns={'Quantidade': 'Frequencia'})\n","\n","# calcular a porcentagem de cada variante em relação ao total do mês\n","dfLinMes_PT['Porcentagem'] = round((dfLinMes_PT['Frequencia'] / dfLinMes_PT['Frequencia'].sum())*100,1)\n","\n","# classificar do maior pro menor\n","dfLinMes_PT = dfLinMes_PT.sort_values('Porcentagem', ascending=False)\n","\n","# dropar índice\n","dfLinMes_PT = dfLinMes_PT.drop('index', axis=1)\n","\n","# traduzir\n","dfLinMes_EN = dfLinMes_PT.replace({'Outras': 'Others'})\n","dfLinMes_ES = dfLinMes_PT.replace({'Outras': 'Otras'})\n","\n","\n","# exportar\n","dfLinMes_PT[:3].to_csv('dfLinhagensMes_PT.csv', index=False)\n","dfLinMes_EN[:3].to_csv('dfLinhagensMes_EN.csv', index=False)\n","dfLinMes_ES[:3].to_csv('dfLinhagensMes_ES.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6knIcxnIuzN_"},"source":["# 7 Análises - gráficos da série histórica"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["# chamar função para criar as linhagens da série histórica\n","dados_lin = cria_linhagem(dados)\n","\n","# excluir Jan 2020 - começo da pandemia, pouquíssimas amostras (distorce o gráfico)\n","dados_lin = dados_lin.query('Período != \"Jan 2020\"')"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":338,"status":"ok","timestamp":1638638840542,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"QvzYIZqlr5cG"},"outputs":[{"data":{"text/plain":["P.1.* (Gama)                   58075\n","BA.1.* (Omicron)               49880\n","B.1.617.2+AY.* (Delta)         48690\n","BA.5.* (Omicron)               34138\n","BA.2.* (Omicron)               14518\n","Outras                          7130\n","B.1.1.28                        5598\n","BA.4.* (Omicron)                5382\n","XBB.* (Omicron)                 5178\n","P.2                             4913\n","B.1.1.33                        3933\n","XBB.1.5.70.*+GK.* (Omicron)     3530\n","JD.1.* (Omicron)                3158\n","JN.1.*+BA.2.86.* (Omicron)      2326\n","FE.1.* (Omicron)                1886\n","B.1.1.7 (Alfa)                  1401\n","B.1.1                           1015\n","Name: Linhagens relevantes, dtype: int64"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["# Linhagens mais relevantes serão mostradas nos gráficos\n","linhagens_relevantes = ['B.1.1', 'B.1.1.28', 'B.1.1.33', 'P.2',\n","                        'B.1.1.7 (Alfa)', \n","                        'B.1.617.2+AY.* (Delta)', \n","                        'P.1.* (Gama)', \n","                        'BA.1.* (Omicron)', 'BA.2.* (Omicron)', \n","                        'BA.4.* (Omicron)', 'BA.5.* (Omicron)',\n","                        'XBB.* (Omicron)', 'FE.1.* (Omicron)',\n","                        'XBB.1.5.70.*+GK.* (Omicron)',\n","                        'JD.1.* (Omicron)',\n","                        'JN.1.*+BA.2.86.* (Omicron)']\n","\n","# criar uma coluna 'Linhagens relevantes' ; quem não for relevante, será classificada como 'Outras'\n","dados_lin['Linhagens relevantes'] = dados_lin['Linhagem'].apply(lambda x: x if x in linhagens_relevantes else 'Outras')\n","dados_lin['Linhagens relevantes'].value_counts() "]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1638638894841,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"1QNSaFhg9P5f","outputId":"c4add38b-f479-4771-9956-e7daa17c975b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Data</th>\n","      <th>Período</th>\n","      <th>Região</th>\n","      <th>Estado</th>\n","      <th>Laboratório</th>\n","      <th>Linhagens relevantes</th>\n","      <th>Quantidade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-02-01</td>\n","      <td>Fev 2020</td>\n","      <td>Nordeste</td>\n","      <td>Bahia</td>\n","      <td>Outros</td>\n","      <td>B.1.1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-02-01</td>\n","      <td>Fev 2020</td>\n","      <td>Sudeste</td>\n","      <td>Espírito Santo</td>\n","      <td>FIOCRUZ</td>\n","      <td>Outras</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Data   Período    Região          Estado Laboratório  \\\n","0 2020-02-01  Fev 2020  Nordeste           Bahia      Outros   \n","1 2020-02-01  Fev 2020   Sudeste  Espírito Santo     FIOCRUZ   \n","\n","  Linhagens relevantes  Quantidade  \n","0                B.1.1           1  \n","1               Outras           1  "]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["# selecionar apenas algumas colunas\n","agrupado_linhagem = dados_lin[['Virus_name', 'Data', 'Período', 'Região', 'Estado', 'Laboratório', 'Linhagens relevantes']]\n","\n","# Agrupar - Não incluir 'Linhagem' senão ficará uma tabela enorme para exportar\n","agrupado_linhagem = agrupado_linhagem.groupby(['Data', 'Período', 'Região', \n","                                               'Estado', 'Laboratório', 'Linhagens relevantes']).count()\n","\n","# resetar índice\n","agrupado_linhagem = agrupado_linhagem.reset_index()\n","\n","# # renomear colunas\n","agrupado_linhagem = agrupado_linhagem.rename(columns={'Virus_name': 'Quantidade'})\n","agrupado_linhagem.head(2)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# traduzir EN e ES\n","dic_replace_regiao_EN = {'Norte': 'North', \n","                         'Nordeste': 'Northeast',\n","                         'Sudeste': 'Southeast', \n","                         'Sul': 'South',\n","                         'Centro-oeste': 'Central-west',\n","                         'Outras': 'Others',\n","                         'Outros': 'Others'}\n","\n","dic_regex_EN = {'Fev': 'Feb', 'Abr': 'Apr', 'Mai': 'May',\n","                'Ago': 'Aug', 'Set': 'Sep', 'Out': 'Oct',\n","                'Dez': 'Dec', \n","                'Gama': 'Gamma', 'Alfa': 'Alpha'}\n","\n","dic_replace_regiao_ES = {'Nordeste': 'Noreste',\n","                         'Sudeste': 'Sureste', \n","                         'Sul': 'Sur',\n","                         'Outras': 'Otras',\n","                         'Outros': 'Otros'}\n","\n","dic_regex_ES = {'Jan': 'Ene', 'Fev': 'Feb', 'Mai': 'May',\n","                'Set': 'Sep', 'Out': 'Oct', 'Dez': 'Dic'}\n","\n","agrupado_linhagem_EN = agrupado_linhagem.replace(dic_replace_regiao_EN)\n","agrupado_linhagem_EN = agrupado_linhagem_EN.replace(regex=dic_regex_EN)\n","agrupado_linhagem_EN = agrupado_linhagem_EN.rename(columns={'Data': 'Date', 'Período': 'Period',\n","                                                            'Região': 'Region', 'Estado': 'State',\n","                                                            'Variante': 'Variant', \n","                                                            'Laboratório': 'Laboratory',\n","                                                            'Linhagens relevantes': 'Relevant lineages',\n","                                                            'Quantidade': 'Quantity'})\n","\n","agrupado_linhagem_ES = agrupado_linhagem.replace(dic_replace_regiao_ES)\n","agrupado_linhagem_ES = agrupado_linhagem_ES.replace(regex=dic_regex_ES)\n","agrupado_linhagem_ES = agrupado_linhagem_ES.rename(columns={'Data': 'Fecha',\n","                                                            'Região': 'Región',\n","                                                            'Laboratório': 'Laboratorio',\n","                                                            'Linhagens relevantes': 'Lineajes relevantes',\n","                                                            'Quantidade': 'Cantidad'})"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1638638900136,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"t80mwselIMzF"},"outputs":[],"source":["# exportar\n","agrupado_linhagem.to_csv(\"dfLinhagens_PT.csv\", index=False)\n","agrupado_linhagem_EN.to_csv(\"dfLinhagens_EN.csv\", index=False)\n","agrupado_linhagem_ES.to_csv(\"dfLinhagens_ES.csv\", index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YCYHu-NLMf_n"},"source":["# 8 Mapas - Genomas/Casos confirmados "]},{"cell_type":"markdown","metadata":{},"source":["### 8.1 Genomas"]},{"cell_type":"code","execution_count":106,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1638638931950,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"cCEcQcjWakYU","outputId":"b8e9f5dc-d028-4612-899e-06dc8f370cf6"},"outputs":[],"source":["# copiar df\n","dados2 = dados.copy()\n","# remover onde 'Estado == NaN'\n","dados2 = dados2[dados2['Estado'].notna()]\n","\n","# selecionar apenas algumas colunas\n","df_genomas = dados2[[\"Virus_name\", \"Data\", \"Período\", \"Estado\"]]\n","\n","# agrupar Genomas pela 'data' e pelo 'Estado' e fazer a contagem; resetar índice\n","df_genomas = df_genomas.groupby([\"Data\", \"Período\", \"Estado\"]).count().reset_index()\n","\n","# renomear coluna\n","df_genomas = df_genomas.rename(columns={\"Virus_name\": \"Genomas sequenciados\"})"]},{"cell_type":"code","execution_count":107,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":896},"executionInfo":{"elapsed":1164,"status":"ok","timestamp":1638638934726,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"3CtHvvv1A2VC","outputId":"4bacb628-d479-4ca5-caf6-0176de5edd78"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Estado</th>\n","      <th>Genomas sequenciados</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Acre</td>\n","      <td>1607</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Alagoas</td>\n","      <td>3278</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Amapá</td>\n","      <td>1302</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Amazonas</td>\n","      <td>11787</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bahia</td>\n","      <td>10398</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Ceará</td>\n","      <td>11443</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Distrito Federal</td>\n","      <td>3475</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Espírito Santo</td>\n","      <td>4579</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Goiás</td>\n","      <td>9187</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Maranhão</td>\n","      <td>1407</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Mato Grosso</td>\n","      <td>1364</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Mato Grosso do Sul</td>\n","      <td>3419</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Minas Gerais</td>\n","      <td>9924</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Paraná</td>\n","      <td>13092</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Paraíba</td>\n","      <td>3823</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>Pará</td>\n","      <td>3316</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>Pernambuco</td>\n","      <td>8633</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Piauí</td>\n","      <td>644</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>Rio Grande do Norte</td>\n","      <td>2555</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Rio Grande do Sul</td>\n","      <td>9747</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>Rio de Janeiro</td>\n","      <td>26821</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Rondônia</td>\n","      <td>1835</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>Roraima</td>\n","      <td>718</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>Santa Catarina</td>\n","      <td>11232</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Sergipe</td>\n","      <td>968</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>São Paulo</td>\n","      <td>90875</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>Tocantins</td>\n","      <td>2713</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Estado  Genomas sequenciados\n","0                  Acre                  1607\n","1               Alagoas                  3278\n","2                 Amapá                  1302\n","3              Amazonas                 11787\n","4                 Bahia                 10398\n","5                 Ceará                 11443\n","6      Distrito Federal                  3475\n","7        Espírito Santo                  4579\n","8                 Goiás                  9187\n","9              Maranhão                  1407\n","10          Mato Grosso                  1364\n","11   Mato Grosso do Sul                  3419\n","12         Minas Gerais                  9924\n","13               Paraná                 13092\n","14              Paraíba                  3823\n","15                 Pará                  3316\n","16           Pernambuco                  8633\n","17                Piauí                   644\n","18  Rio Grande do Norte                  2555\n","19    Rio Grande do Sul                  9747\n","20       Rio de Janeiro                 26821\n","21             Rondônia                  1835\n","22              Roraima                   718\n","23       Santa Catarina                 11232\n","24              Sergipe                   968\n","25            São Paulo                 90875\n","26            Tocantins                  2713"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["# agrupar pelo Estado = total de genomas/Estado\n","df_genomas = df_genomas.groupby(\"Estado\").sum().reset_index()\n","df_genomas"]},{"cell_type":"markdown","metadata":{},"source":["### 8.2 Casos covid"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UF</th>\n","      <th>Casos</th>\n","      <th>Estado</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AC</td>\n","      <td>168785</td>\n","      <td>Acre</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>346836</td>\n","      <td>Alagoas</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AM</td>\n","      <td>641988</td>\n","      <td>Amazonas</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   UF   Casos    Estado\n","0  AC  168785      Acre\n","1  AL  346836   Alagoas\n","2  AM  641988  Amazonas"]},"execution_count":105,"metadata":{},"output_type":"execute_result"}],"source":["# renomear colunas\n","casos_full_filtrado = casos_full_filtrado.rename(columns={'casosNovos': 'Casos',\n","                                                          'estado': 'UF'})\n","\n","# Somar total de casos por 'UF'\n","df_casos = casos_full_filtrado.groupby('UF').sum().reset_index()\n","\n","# criar a coluna 'Estado'\n","df_casos['Estado'] = df_casos['UF'].map(dict_sigla_para_estado)\n","df_casos.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GU-x0g3PV8Sc"},"source":["### 8.3 Unir os dfs de Genomas e Casos (unir pelo 'Estado')"]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":896},"executionInfo":{"elapsed":786,"status":"ok","timestamp":1638638949048,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"mzRGjX0YWVlD","outputId":"8f4ed51e-b5c5-4b77-8e11-2e44112c7f72"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UF</th>\n","      <th>Casos</th>\n","      <th>Estado</th>\n","      <th>Genomas sequenciados</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AC</td>\n","      <td>168785</td>\n","      <td>Acre</td>\n","      <td>1607</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>346836</td>\n","      <td>Alagoas</td>\n","      <td>3278</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AM</td>\n","      <td>641988</td>\n","      <td>Amazonas</td>\n","      <td>11787</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AP</td>\n","      <td>191454</td>\n","      <td>Amapá</td>\n","      <td>1302</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BA</td>\n","      <td>1861497</td>\n","      <td>Bahia</td>\n","      <td>10398</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>CE</td>\n","      <td>1522256</td>\n","      <td>Ceará</td>\n","      <td>11443</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DF</td>\n","      <td>942041</td>\n","      <td>Distrito Federal</td>\n","      <td>3475</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ES</td>\n","      <td>1391158</td>\n","      <td>Espírito Santo</td>\n","      <td>4579</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>GO</td>\n","      <td>2030728</td>\n","      <td>Goiás</td>\n","      <td>9187</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>MA</td>\n","      <td>500694</td>\n","      <td>Maranhão</td>\n","      <td>1407</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>MG</td>\n","      <td>4299532</td>\n","      <td>Minas Gerais</td>\n","      <td>9924</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>MS</td>\n","      <td>631961</td>\n","      <td>Mato Grosso do Sul</td>\n","      <td>3419</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>MT</td>\n","      <td>916975</td>\n","      <td>Mato Grosso</td>\n","      <td>1364</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>PA</td>\n","      <td>898635</td>\n","      <td>Pará</td>\n","      <td>3316</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>PB</td>\n","      <td>725199</td>\n","      <td>Paraíba</td>\n","      <td>3823</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>PE</td>\n","      <td>1231861</td>\n","      <td>Pernambuco</td>\n","      <td>8633</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>PI</td>\n","      <td>438436</td>\n","      <td>Piauí</td>\n","      <td>644</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>PR</td>\n","      <td>3022165</td>\n","      <td>Paraná</td>\n","      <td>13092</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>RJ</td>\n","      <td>2938492</td>\n","      <td>Rio de Janeiro</td>\n","      <td>26821</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>RN</td>\n","      <td>600492</td>\n","      <td>Rio Grande do Norte</td>\n","      <td>2555</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>RO</td>\n","      <td>503039</td>\n","      <td>Rondônia</td>\n","      <td>1835</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>RR</td>\n","      <td>193589</td>\n","      <td>Roraima</td>\n","      <td>718</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>RS</td>\n","      <td>3129343</td>\n","      <td>Rio Grande do Sul</td>\n","      <td>9747</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>SC</td>\n","      <td>2079235</td>\n","      <td>Santa Catarina</td>\n","      <td>11232</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>SE</td>\n","      <td>367744</td>\n","      <td>Sergipe</td>\n","      <td>968</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>SP</td>\n","      <td>6841625</td>\n","      <td>São Paulo</td>\n","      <td>90875</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>TO</td>\n","      <td>381140</td>\n","      <td>Tocantins</td>\n","      <td>2713</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    UF    Casos               Estado  Genomas sequenciados\n","0   AC   168785                 Acre                  1607\n","1   AL   346836              Alagoas                  3278\n","2   AM   641988             Amazonas                 11787\n","3   AP   191454                Amapá                  1302\n","4   BA  1861497                Bahia                 10398\n","5   CE  1522256                Ceará                 11443\n","6   DF   942041     Distrito Federal                  3475\n","7   ES  1391158       Espírito Santo                  4579\n","8   GO  2030728                Goiás                  9187\n","9   MA   500694             Maranhão                  1407\n","10  MG  4299532         Minas Gerais                  9924\n","11  MS   631961   Mato Grosso do Sul                  3419\n","12  MT   916975          Mato Grosso                  1364\n","13  PA   898635                 Pará                  3316\n","14  PB   725199              Paraíba                  3823\n","15  PE  1231861           Pernambuco                  8633\n","16  PI   438436                Piauí                   644\n","17  PR  3022165               Paraná                 13092\n","18  RJ  2938492       Rio de Janeiro                 26821\n","19  RN   600492  Rio Grande do Norte                  2555\n","20  RO   503039             Rondônia                  1835\n","21  RR   193589              Roraima                   718\n","22  RS  3129343    Rio Grande do Sul                  9747\n","23  SC  2079235       Santa Catarina                 11232\n","24  SE   367744              Sergipe                   968\n","25  SP  6841625            São Paulo                 90875\n","26  TO   381140            Tocantins                  2713"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["# merge com o dataframe que tem a quantidade total de genomas/estado \n","df_casos_genomas = pd.merge(df_casos, df_genomas, on='Estado')\n","df_casos_genomas"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1638638952312,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"esScR1ehYKh9","outputId":"991a3dbe-5edb-4390-cf99-bd76a8bfe014"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UF</th>\n","      <th>Casos</th>\n","      <th>Estado</th>\n","      <th>Genomas sequenciados</th>\n","      <th>casos_dividido_por_100k</th>\n","      <th>Genomas/100 mil casos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AC</td>\n","      <td>168785</td>\n","      <td>Acre</td>\n","      <td>1607</td>\n","      <td>1.68785</td>\n","      <td>952.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AL</td>\n","      <td>346836</td>\n","      <td>Alagoas</td>\n","      <td>3278</td>\n","      <td>3.46836</td>\n","      <td>945.1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   UF   Casos   Estado  Genomas sequenciados  casos_dividido_por_100k  \\\n","0  AC  168785     Acre                  1607                  1.68785   \n","1  AL  346836  Alagoas                  3278                  3.46836   \n","\n","   Genomas/100 mil casos  \n","0                  952.1  \n","1                  945.1  "]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["# dividir os casos confirmados por 100.000\n","df_casos_genomas['casos_dividido_por_100k'] = df_casos_genomas['Casos']/10**5\n","\n","# dividir o total de genomas por casos_dividido_por_100k\n","resultado = df_casos_genomas['Genomas sequenciados'] / df_casos_genomas['casos_dividido_por_100k'] \n","\n","# arredondar para 1 casa decimal\n","df_casos_genomas['Genomas/100 mil casos'] = round(resultado, 1)\n","df_casos_genomas.head(2)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# traduzir EN e ES\n","df_casos_genomas_EN = df_casos_genomas.rename(columns={'Estado': 'State', \n","                                                       'Genomas sequenciados': 'Genomes sequenced',\n","                                                       'Genomas/100 mil casos': 'Genomes/100K cases', \n","                                                       'Casos': 'Cases'})\n","\n","df_casos_genomas_ES = df_casos_genomas.rename(columns={'Genomas sequenciados': 'Genomas secuenciados'})"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":523,"status":"ok","timestamp":1638638959087,"user":{"displayName":"Vanessa Cardoso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj5fCuH6e0CsZpO0czWCuvDJCEYMzWqBR1AI6V9Aw=s64","userId":"11408999963211222080"},"user_tz":180},"id":"GIzR3KPHMsUI"},"outputs":[],"source":["# exportar\n","df_casos_genomas.to_csv('dfMapa_PT.csv', index=False)\n","df_casos_genomas_EN.to_csv('dfMapa_EN.csv', index=False)\n","df_casos_genomas_ES.to_csv('dfMapa_ES.csv', index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMVRZpSTmo3SHw63lPadp9Z","collapsed_sections":[],"mount_file_id":"1wai4-GPTrNPF8cnYt2u5WMjceT8o5SQT","name":"Analises-dos-Dados-Total-GISAID.ipynb","provenance":[]},"interpreter":{"hash":"fb9f30d00fa3f7dc933615f4feddfc9981a5d0245c7401bc2cabbc3792724f14"},"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
